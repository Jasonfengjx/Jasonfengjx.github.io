<div class="about-container">
    <div class="page-header">
        <h1>关于我</h1>
        <p class="subtitle">算法工程师 / 大模型研究 / 搜索推荐</p>
    </div>

    <div class="about-content single-column">
        <h2 class="section-title">📌 实习经历</h2>

        <details class="about-item">
            <summary>算法工程师 — 滴滴 花小猪打车策略算法团队（2025.10-2026.1）</summary>
            <div class="about-body">
                <h4>司乘取消判责大模型训练优化</h4>
                <p>线上baseline模型为经过lora sft和grpo强化学习训练的qwen3-8b模型。针对原始qwen3-8b模型进行full sft训练，引入flash attention加速训练（资源消耗-33%，精准度+0.5pp，recall+2.87pp）。针对bad case与下游团队合作完善标注，并使用deepseek-R1进行思维链标注与人工筛选。</p>

                <h4>司乘取消多任务模型优化</h4>
                <p>基于PLE的多任务模型（expert、tower、gate、poso）。通过消融实验去除了负向作用的gate结构（AUC增长0.2pp）。引入senet+blinear进行特征交叉，提升了司机、乘客及司乘取消的AUC。实验对比了wukong交叉方法与senet+bilinear的效果差异。</p>
            </div>
        </details>

        <details class="about-item">
            <summary>大模型算法工程师 — 阿里 ICBU搜索算法团队（2025.6-2025.9）</summary>
            <div class="about-body">
                <h4>多语言商品大模型预训练任务</h4>
                <p>解决大模型多语言诅咒问题，收集整理开源及爬取数据（亚马逊7种语言100万条商品数据），进行结构化改写与配比。在Qwen3-4b和14b上进行full CPT和lora CPT。针对主体与属性抽取问题，收集数据并使用GPT进行CoT标注筛选，SFT后Qwen3-4b在主体属性抽取上显著提升（主体good+37.13%），线上GMV+3%。</p>

                <h4>相关性模型升级</h4>
                <p>对预训练模型进行相关性任务SFT。Qwen3-14b在多语言相关性任务上表现显著提升（如es语言3档位precision+1.47%）。利用模型标注数据训练线上BERT模型，线上A/B实验显示搜索实曝光创建订单+5.3%，引导支付买家数+3.15%。</p>
            </div>
        </details>

        <details class="about-item">
            <summary>大模型算法工程师 — 华为 AI算法部（ICT）（2025.1-2025.6）</summary>
            <div class="about-body">
                <h4>DeepDive 基于ReAct的深度研究项目</h4>
                <p>以ReAct框架为原型，分解复杂问题，负责Agent搜索工具及系统功能开发。在通信领域小区故障场景落地，构建工作流并与上下游合作。通过调整工作流、Prompt及RAG方法调优，最终ACC达到70%，校准误差率控制在40以内。</p>

                <h4>基于强化学习GRPO的大模型搜索工具调用增强</h4>
                <p>增强大模型专业领域答题能力。整理ICT领域3k条数据，使用Qwen2.5-7b进行搜索工具调用能力增强。设计结果格式与正确性奖励，调整Prompt解决reward hacking问题，ACC从0.45提升至0.77。</p>
            </div>
        </details>

        <h2 class="section-title">💡 项目经历</h2>

        <details class="about-item">
            <summary>WSDM Cup 2025 多语言聊天机器人竞技场预测竞赛 — Kaggle银牌 (Top 4%)</summary>
            <div class="about-body">
                <p><strong>背景：</strong>开发模型判断获胜LLM，改进人机互动。</p>
                <p><strong>方法：</strong>基于Gemma2-9b进行Lora微调。使用3072 token长度，动态batchsize加速，调整prompt顺序消除position bias，补充mlabonne/orpo-dpo-mix-40k数据集并利用soft label优化。</p>
                <p><strong>结果：</strong>最终模型ACC达到0.705。</p>
            </div>
        </details>

        <details class="about-item">
            <summary>Triple-effect correction for Cell Painting data... — Nature Communications (共一)</summary>
            <div class="about-body">
                <p><strong>背景：</strong>同构多源数据归一化，抑制噪声并保留内在分布。</p>
                <p><strong>方法：</strong>使用GMVAE+对比学习解决数据不一致。受迁移学习启发，提取预训练模型多层特征融合。提出联合训练策略解决分布差异。</p>
            </div>
        </details>

        <h2 class="section-title">🌟 个人特质</h2>
        <details class="about-item">
            <summary>个人特质</summary>
            <div class="about-body">
                <p>热爱运动、沟通性强，能够承担高强度工作。</p>
            </div>
        </details>
    </div>
</div>
